---
title: 吴恩达·机器学习课程（六）
draft: false
description: 第六周学习内容：机器学习系统的设计
tags:
  - courses notes
  - machine learning
categories:
  - machine learning
mathjax: true
abbrlink: 275c94aa
date: 2020-04-30 21:47:39
---

# 应用机器学习的建议

## 决定下一步做什么

学习旅程中，当你碰到问题时，可能会把大量的时间浪费在毫无意义的尝试之中，本章节主要讲解在设计机器学习系统时碰到问题，该如何选择一条最合适、最正确的道路。

照旧以正则化线性回归预测房价问题为例，当你将学习获得的假设函数放到一组新的房屋样本上进行测试时，发现预测房价产生了巨大误差，现在需要对算法进行一定的改进，该怎么做呢？

你可以选择如下：

- 获得更多的训练集样本
- 尝试减少特征数量
- 尝试增加特征数量
- 尝试增加多项式特征
- 尝试减少正则化参数$\lambda$
- 尝试增加正则化参数$\lambda$

当你选择其中一个方案，花费了大量时间，但最后结果却不尽如人意，就是在浪费时间，所以，接下来将学习机器学习诊断法，即学习如何对一个学习生成的假设函数进行评价以及如何改进一个机器学习模型。

## 评估一个假设

当确定学习算法，并通过算法确定模型参数，现在需要解决的问题是如何评价构建的模型的。

因此，我们需要使用策略来评估假设函数。

第一步，获取用于评估数据。

这里选择使用留出法(`hold out`)，即将数据集分成训练集(`train set`)和测试集(`test set`)，通常用70%的数据作为训练集来确定假设函数的参数，用剩下的30%的数据作为测试集来测试假设函数。需要注意的是，这里数据的选择也需要尽可能的随机。

第二步，选择评估方法。

对于线性回归模型，可以利用测试集数据计算代价函数$J$，通过与训练集的代价函数比较来评估。

对于逻辑回归模型，除了使用测试集计算代价函数意外，还可以通过计算测试集中预测错误的概率来评估。

## 模型选择和交叉验证集

现在我们需要从10个不同次数的二项式模型之间来选择最好的那个假设函数。

显然越高次数的多项式模型越能够适应训练集，但这很多时候会使得假设函数的泛化能力减弱，所以需要在多个模型中使用交叉验证集来帮助选择模型。

在交叉验证集中，使用60%的数据作为训练集，使用20%的数据作为交叉验证集(`cross validation set`)，使用20%的数据作为测试集。

模型选择的方法为：

1. 使用训练集训练出10个模型
2. 用10个模型分别对交叉验证集计算得出交叉验证误差(代价函数的值)
3. 选取代价函数值最小的模型
4. 用步骤3中选出的模型对测试集计算得出泛化误差(代价函数的值)

## 诊断偏差和方差

当运行一个学习算法时，算法表现不理想，多半是出现两种情况：偏差(`bias`)较大或者方差(`variance`)较大。换而言之就是出现欠拟合和过拟合现象。

那么这两种情况，哪个和偏差有关，哪个和方差有关，或者是不是两个都有关？

这里采用的方法是通过将训练集和交叉验证集的代价函数误差与多项式的最高次数绘制在图表上来分析，即纵坐标为代价函数$J$，横坐标为多项式的最高次数$d$。

对于训练集，当$d$较小时，模型拟合程度较低，$J$较大；随着$d$增大，拟合程度提高，$J$减小。

对于交叉验证集，当$d$较小时，模型拟合程度较低，$J$较大；随着$d$增大，误差呈现先减小后增大的趋势，转折点时模型开始过拟合训练集。

如下图，当交叉验证集误差较大时可以判断出时方差还是偏差问题了。

![图1](/images/Machine_Learning_Lecture6_1.png)

训练集误差和交叉验证集误差近似时：偏差/欠拟合

交叉验证集误差远大于训练集误差时：方差/过拟合

## 正则化和偏差/方差

在训练模型中一般会使用正则化来防止过拟合，但是当使用的正则话参数$\lambda$过大，会导致高偏差；$\lambda$过小又会导致高偏差，那么又该如何选择正则化参数$\lambda$呢？

一般采用的时选择一系列想要测试的$\lambda$值，通常是$0-10$之间，再通过交叉验证集进行评估。

步骤如下：

1. 使用训练集训练出12个不同程度正则化的模型
2. 用12个模型分别对交叉验证集计算得出交叉验证误差
3. 选择交叉验证误差最小的模型
4. 运用步骤3中选出的模型对测试集计算得出泛化误差

同时将训练集和交叉验证集的代价函数值与$lambda$绘制在如下图表中，可以得出：

- 当$\lambda$较小时，训练集误差较小(过拟合)，而交叉验证集误差较大；
- 随着$\lambda$增大，训练集误差不断增加(欠拟合)，而交叉验证集误差则先减小后增大。

![图2](/images/Machine_Learning_Lecture6_2.png)

## 学习曲线

学习曲线(`learing curves`)是将训练集误差和交叉验证集误差作为训练集样本数量的函数绘制的图像。

学习曲线通常被用来判断某个学习算法是否处于偏差、方差问题。

思想是：当训练集较小时，训练的模型能够很好的使用训练数据，但却没有很好的泛化能力，即无法很好的适应交叉验证集和测试集数据。

如下图，当样本足够多时训练集和交叉验证集的代价函数趋近于平行坐标轴，可认为是出于高偏差状态，即样本的增加不会改变训练集和交叉验证集的误差。

![图3](/images/Machine_Learning_Lecture6_3.png)

可知，在高偏差欠拟合情况下，增加训练集的数据不一定能带来帮助。

如下图，当交叉验证集误差远大于训练集误差时，显然是处于高方差状态，这时往训练集增加更多的数据是可以提高模型的效果的。


![图4](/images/Machine_Learning_Lecture6_4.png)

## 决定下一步做什么

借助以上的一些方法，可以回答最开始的问题了。

通过对模型的有效评估而选择对应解决问题的策略，避免盲目徒劳，大大节省时间。

对于前面的六种方案，可以总结如下：

- 获得更多的训练集样本——解决高方差
- 尝试减少特征数量——解决高方差
- 尝试增加特征数量——解决高偏差
- 尝试增加多项式特征——解决高偏差
- 尝试减少正则化参数$\lambda$——解决高偏差
- 尝试增加正则化参数$\lambda$——解决高方差

对于神经网络的高方差和高偏差问题：

当神经网络较小时，类似于回归问题中参数较少情况，容易导致高偏差和欠拟合；当使用较大神经网络时，类似于参数较多，容易导致高方差和过拟合，虽然计算代价较大，但是可以通过正则化来适应数据。

一般情况下选择较大的神经网络并采用正则化处理会比采用较小的神经网络效果要好。

对于神经网络中隐藏层的层数选择，通常也采用交叉验证集的方法，对不同层数的神经网络进行评估再选择。

故在设计机器学习系统时应该在尽可能快的设计好系统，然后再对系统进行评估和优化，而不是把更多的时间浪费在整理数据获设计模型上。

# 机器学习系统的设计

## 首先要做什么

本章节以构建垃圾邮件过滤系统为例来说明设计机器学习系统的工作优先顺序。

显然，这是一个归属于监督学习的分类问题。

首先需要决定的是如何选择并表达特征向量$x$，我们可以选择一个由100个最常出现在垃圾邮件中的词所构成的列表，根据这些词是否出现在邮件中，来获得我们的特征向量。

为了构建这个分类器算法，还有以下工作：

1. 收集更多的数据，增加垃圾邮件和非垃圾邮件的样本
2. 基于邮件的头部信息开发复杂特征
3. 基于邮件正文信息开发复杂特征
4. 为探测错误拼写开发复杂特征

如同前一章节，我们需要针对系统进行评估然后再对以上工作进行优先排序，避免浪费大量时间进行无效工作。

## 误差分析

构建学习算法的推荐方法：

1. 从一个简单的能快速实现的算法开始，实现这个算法然后使用交叉验证集来测试它；
2. 绘制学习曲线，决定增加更多数据还是增加特征量等能够对系统有帮助；
3. 错误分析：手动测试交叉验证机中算法产生错误预测的样本，找寻这些样本的某些系统性趋势。

以垃圾邮件过滤系统为例，误差分析要做的就是手动地针对交叉验证集预测误差的样本进行分类，比如医药品垃圾邮件，仿冒品垃圾邮件或者密码窃取邮件。然后看分类器对哪一组邮件地预测误差最大，并着手优化。

思考你认为那些增加哪些特征能够提升算法的分类准确率。

还可以记录错误拼写出现的次数，异常的邮件路由情况出现的次数，然后从出现次数最多的情况着手优化。

此外，进行数值评估是非常重要的。

比如，是否应该将discount/discounts/discounted/discounting处理成同一个词？如果这样做可以改善我们算法，我们会采用一些截词软件。误差分析不能帮助我们做出这类判断，我们只能尝试采用和不采用截词软件这两种不同方案，然后根据数值检验的结果来判断哪一种更好。

## 类偏斜的误差度量

偏斜类(`skewed classes`)指的是训练集样本各类数据量相差过大，比如在癌细胞分类系统中，在训练集中只有0.5%的样本是恶心肿瘤，当不适用学习算法而建立一个在所有情况下都预测肿瘤是良性的模型，那么误差只有0.5%；而通过学习算法训练的模型却有1%的误差。这样，误差的大小就不能作为评判算法效果的有效依据了。

针对这种情况，可以使用查准率(`Precision`)和查全率(`Recall`)来进行评价。

 &nbsp; |  &nbsp; | Actual | Class
 :--: | :----: | :----: | :----:
 &nbsp; | &nbsp;  | 1 | 0
 Predicted | 1 | True Positive | False Positive
 Class | 0 | False Negative |True Negative

如上表，我们将算法预测的结果分成四种情况：

1. 正确肯定(`True Positive,TP`)：预测为真，实际为真
2. 正确否定(`True Negative,TN`)：预测为假，实际为假
3. 错误肯定(`False Positive,FP`)：预测为真，实际为假
4. 错误否定(`False Negative,FN`)：预测为假，实际为真

$P=\frac{TP}{TP+FP}$，即查准率表示**预测有恶性肿瘤的患者中，实际有恶性肿瘤患者的比例**，越高越好；

$R=\frac{TP}{TP+FN}$，即查全率表示**实际有恶性癌肿瘤的患者中被准确检测出来的比例**，越高越好。

这样子，在我们总是预测预测肿瘤是良性的模型中，查准率和查全率均为0。

## 查准率和查全率之间的权衡

实际上，查准率和查全率时一堆矛盾的度量，一般来说，查准率高时，查全率往往偏低，反之亦然。故我们需要对查准率和查全率进行一个权衡取舍了。

如果希望能够更加准确的确保检测出恶性肿瘤的准确性，那么就希望查准率更高；如果希望能够更全面的查出有恶性肿瘤以方便患者的治疗，那么就希望查全率更高。在这里通过设置不同的阀值(`threshold`)来进行控制。即

$$
\text{Predict 1 if }  h_{\theta}(x) \geq threshold
$$

基于相同的训练集可能得到不同的查全率和查准率木星，这里引进$F_1 \text{ Score}$来比较查全率和查准率。

$F_1$是基于查准率和查全率的调和平均来定义的，即：

$$
\frac{1}{F_1} = \frac{1}{2} · (\frac{1}{P} + \frac{1}{R})
$$

此外还有加权调和平均$F_{\beta} = \frac{1}{1+\beta^2} · (\frac{1}{P} + \frac{\beta^2}{R})$

## 机器学习的数据

有研究表明，随着训练集的增大，获得的假设函数的预测准确率也随之增加，即使是较差的学习算法在训练集优势上也可能在效果上超过没有足够训练集的好的算法。

但同样需要注意的是，如果没有足够的特征值来承载足够的信息进行预测，也是不行的。举例而言，只知道房子面积大小，不知道房子年份、地段、房间数量，装修情况等，即使是资深销售人员也无法对房价进行预测。

所以，更多的特征值是为了减少偏差，更多的测试集是为了减少方差，只有在这两个基础上才能够获得比较好的预测函数。