---
title: "吴恩达·机器学习课程（六）"
date: 2020-04-30 21:47:39
draft: false
description: "第六周学习内容：机器学习系统的设计"
tags: 
- courses notes
- machine learning
categories: 
- machine learning
mathjax: true
---

# 应用机器学习的建议

## 决定下一步做什么

学习旅程中，当你碰到问题时，可能会把大量的时间浪费在毫无意义的尝试之中，本章节主要讲解在设计机器学习系统时碰到问题，该如何选择一条最合适、最正确的道路。

照旧以正则化线性回归预测房价问题为例，当你将学习获得的假设函数放到一组新的房屋样本上进行测试时，发现预测房价产生了巨大误差，现在需要对算法进行一定的改进，该怎么做呢？

你可以选择如下：

- 获得更多的训练集样本
- 尝试减少特征数量
- 尝试增加特征数量
- 尝试增加多项式特征
- 尝试减少正则化参数$\lambda$
- 尝试增加正则化参数$\lambda$

当你选择其中一个方案，花费了大量时间，但最后结果却不尽如人意，就是在浪费时间，所以，接下来将学习机器学习诊断法，即学习如何对一个学习生成的假设函数进行评价以及如何改进一个机器学习模型。

## 评估一个假设

当确定学习算法，并通过算法确定模型参数，现在需要解决的问题是如何评价构建的模型的。

因此，我们需要使用策略来评估假设函数。

第一步，获取用于评估数据。

这里选择使用留出法(`hold out`)，即将数据集分成训练集(`train set`)和测试集(`test set`)，通常用70%的数据作为训练集来确定假设函数的参数，用剩下的30%的数据作为测试集来测试假设函数。需要注意的是，这里数据的选择也需要尽可能的随机。

第二步，选择评估方法。

对于线性回归模型，可以利用测试集数据计算代价函数$J$，通过与训练集的代价函数比较来评估。

对于逻辑回归模型，除了使用测试集计算代价函数意外，还可以通过计算测试集中预测错误的概率来评估。

## 模型选择和交叉验证集

现在我们需要从10个不同次数的二项式模型之间来选择最好的那个假设函数。

显然越高次数的多项式模型越能够适应训练集，但这很多时候会使得假设函数的泛化能力减弱，所以需要在多个模型中使用交叉验证集来帮助选择模型。

在交叉验证集中，使用60%的数据作为训练集，使用20%的数据作为交叉验证集(`cross validation set`)，使用20%的数据作为测试集。

模型选择的方法为：

1. 使用训练集训练出10个模型
2. 用10个模型分别对交叉验证集计算得出交叉验证误差(代价函数的值)
3. 选取代价函数值最小的模型
4. 用步骤3中选出的模型对测试集计算得出泛化误差(代价函数的值)

## 诊断偏差和方差

当运行一个学习算法时，算法表现不理想，多半是出现两种情况：偏差(`bias`)较大或者方差(`variance`)较大。换而言之就是出现欠拟合和过拟合现象。

那么这两种情况，哪个和偏差有关，哪个和方差有关，或者是不是两个都有关？

这里采用的方法是通过将训练集和交叉验证集的代价函数误差与多项式的最高次数绘制在图表上来分析，即纵坐标为代价函数$J$，横坐标为多项式的最高次数$d$。

对于训练集，当$d$较小时，模型拟合程度较低，$J$较大；随着$d$增大，拟合程度提高，$J$减小。

对于交叉验证集，当$d$较小时，模型拟合程度较低，$J$较大；随着$d$增大，误差呈现先减小后增大的趋势，转折点时模型开始过拟合训练集。

如下图，当交叉验证集误差较大时可以判断出时方差还是偏差问题了。

![图1](/images/Machine_Learning_Lecture6_1.png)

训练集误差和交叉验证集误差近似时：偏差/欠拟合

交叉验证集误差远大于训练集误差时：方差/过拟合

## 正则化和偏差/方差

在训练模型中一般会使用正则化来防止过拟合，但是当使用的正则话参数$\lambda$过大，会导致高偏差；$\lambda$过小又会导致高偏差，那么又该如何选择正则化参数$\lambda$呢？

一般采用的时选择一系列想要测试的$\lambda$值，通常是$0-10$之间，再通过交叉验证集进行评估。

步骤如下：

1. 使用训练集训练出12个不同程度正则化的模型
2. 用12个模型分别对交叉验证集计算得出交叉验证误差
3. 选择交叉验证误差最小的模型
4. 运用步骤3中选出的模型对测试集计算得出泛化误差

同时将训练集和交叉验证集的代价函数值与$lambda$绘制在如下图表中，可以得出：

- 当$\lambda$较小时，训练集误差较小(过拟合)，而交叉验证集误差较大；
- 随着$\lambda$增大，训练集误差不断增加(欠拟合)，而交叉验证集误差则先减小后增大。

![图2](/images/Machine_Learning_Lecture6_2.png)

## 学习曲线

学习曲线(`learing curves`)是将训练集误差和交叉验证集误差作为训练集样本数量的函数绘制的图像。

学习曲线通常被用来判断某个学习算法是否处于偏差、方差问题。

思想是：当训练集较小时，训练的模型能够很好的使用训练数据，但却没有很好的泛化能力，即无法很好的适应交叉验证集和测试集数据。

如下图，当样本足够多时训练集和交叉验证集的代价函数趋近于平行坐标轴，可认为是出于高偏差状态，即样本的增加不会改变训练集和交叉验证集的误差。

![图3](/images/Machine_Learning_Lecture6_3.png)

可知，在高偏差欠拟合情况下，增加训练集的数据不一定能带来帮助。

如下图，当交叉验证集误差远大于训练集误差时，显然是处于高方差状态，这时往训练集增加更多的数据是可以提高模型的效果的。


![图4](/images/Machine_Learning_Lecture6_4.png)

## 决定下一步做什么

借助以上的一些方法，可以回答最开始的问题了。

通过对模型的有效评估而选择对应解决问题的策略，避免盲目徒劳，大大节省时间。

对于前面的六种方案，可以总结如下：

- 获得更多的训练集样本——解决高方差
- 尝试减少特征数量——解决高方差
- 尝试增加特征数量——解决高偏差
- 尝试增加多项式特征——解决高偏差
- 尝试减少正则化参数$\lambda$——解决高偏差
- 尝试增加正则化参数$\lambda$——解决高方差

# 机器学习系统的设计

## 首先要做什么

## 误差分析

## 类偏斜的误差度量

## 查准率和查全率之间的权衡

## 机器学习的数据

